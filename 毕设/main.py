import sys
import argparse
from pathlib import Path

from config.config import OUTPUT_DIR
from modules.video_processor import VideoProcessor
from modules.pose_estimator import PoseEstimator
from modules.kinematic_analyzer import KinematicAnalyzer
from modules.temporal_model import TemporalModelAnalyzer
from modules.quality_evaluator import QualityEvaluator
from modules.ai_analyzer import AIAnalyzer
from modules.database import DatabaseManager
from utils.visualization import create_comparison_video, plot_angle_curves


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='è·‘æ­¥åŠ¨ä½œåˆ†æç³»ç»Ÿ')
    parser.add_argument('video_path', type=str, help='è§†é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', type=str, default=None, help='è¾“å‡ºç›®å½•')
    parser.add_argument('--visualize', action='store_true', help='ç”Ÿæˆå¯è§†åŒ–ç»“æœ')
    parser.add_argument('--save-db', action='store_true', help='ä¿å­˜åˆ°æ•°æ®åº“')

    args = parser.parse_args()

    # éªŒè¯è§†é¢‘æ–‡ä»¶
    video_path = Path(args.video_path)
    if not video_path.exists():
        print(f"é”™è¯¯: è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨ - {video_path}")
        sys.exit(1)

    # è®¾ç½®è¾“å‡ºç›®å½•
    output_dir = Path(args.output) if args.output else OUTPUT_DIR
    output_dir.mkdir(parents=True, exist_ok=True)

    print("=" * 80)
    print("åŸºäºæ·±åº¦å­¦ä¹ çš„è·‘æ­¥åŠ¨ä½œè§†é¢‘è§£æä¸æŠ€æœ¯è´¨é‡è¯„ä»·ç³»ç»Ÿ")
    print("=" * 80)
    print(f"è§†é¢‘æ–‡ä»¶: {video_path.name}")
    print("=" * 80)

    try:
        # æ‰§è¡Œåˆ†æ
        results = run_analysis_pipeline(str(video_path), output_dir, args.visualize)

        # æ‰“å°ç»“æœ
        print_results(results)

        # ä¿å­˜åˆ°æ•°æ®åº“
        if args.save_db:
            db = DatabaseManager()
            record_id = db.save_analysis(results)
            print(f"\nğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜åˆ°æ•°æ®åº“ (ID: {record_id})")

        print("\n" + "=" * 80)
        print("âœ… åˆ†æå®Œæˆ!")
        print("=" * 80)

    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


def run_analysis_pipeline(video_path: str, output_dir: Path, visualize: bool = False):
    """è¿è¡Œå®Œæ•´åˆ†ææµç¨‹"""

    # 1. è§†é¢‘é¢„å¤„ç†
    print("\n1ï¸âƒ£ è§†é¢‘è¾“å…¥ä¸é¢„å¤„ç†...")
    processor = VideoProcessor(video_path)
    video_info = processor.get_video_info()
    print(f"   åˆ†è¾¨ç‡: {video_info['width']}x{video_info['height']}")
    print(f"   å¸§ç‡: {video_info['fps']:.2f} FPS")
    print(f"   æ—¶é•¿: {video_info['duration']:.2f} ç§’")

    frames, fps = processor.extract_frames(target_fps=30, max_frames=300)
    print(f"   æå–å¸§æ•°: {len(frames)}")

    # 2. å§¿æ€ä¼°è®¡
    print("\n2ï¸âƒ£ äººä½“å§¿æ€ä¼°è®¡ï¼ˆMediaPipe Poseï¼‰...")
    estimator = PoseEstimator()
    keypoints_sequence = estimator.process_frames(frames)

    detected_count = sum(1 for kp in keypoints_sequence if kp['detected'])
    print(f"   æ£€æµ‹æˆåŠŸ: {detected_count}/{len(keypoints_sequence)} å¸§")

    # å¯è§†åŒ–å§¿æ€
    if visualize and detected_count > 0:
        print("   ç”Ÿæˆå§¿æ€å¯è§†åŒ–...")
        pose_frames = []
        for i, kp in enumerate(keypoints_sequence[:10]):  # ä»…å‰10å¸§
            pose_frame = estimator.visualize_pose(frames[i], kp)
            pose_frames.append(pose_frame)

        # ä¿å­˜ç¬¬ä¸€å¸§
        import cv2
        cv2.imwrite(str(output_dir / 'pose_sample.jpg'), pose_frames[0])

    # 3. è¿åŠ¨å­¦ç‰¹å¾è§£æ
    print("\n3ï¸âƒ£ è¿åŠ¨å­¦ç‰¹å¾è§£æ...")
    kinematic_analyzer = KinematicAnalyzer()
    kinematic_results = kinematic_analyzer.analyze_sequence(keypoints_sequence, fps)

    print(f"   æ­¥é¢‘: {kinematic_results['cadence']['cadence']:.1f} æ­¥/åˆ†")
    print(f"   æ­¥æ•°: {kinematic_results['cadence']['step_count']}")
    print(f"   å‚ç›´æŒ¯å¹…: {kinematic_results['vertical_motion']['amplitude']:.2f}")

    # å¯è§†åŒ–è§’åº¦æ›²çº¿
    if visualize and 'angles' in kinematic_results:
        print("   ç”Ÿæˆè§’åº¦æ›²çº¿å›¾...")
        plot_angle_curves(kinematic_results['angles'],
                          str(output_dir / 'angle_curves.png'))

    # 4. æ—¶åºæ·±åº¦å­¦ä¹ åˆ†æ
    print("\n4ï¸âƒ£ æ—¶åºæ·±åº¦å­¦ä¹ åˆ†æï¼ˆLSTM/CNNï¼‰...")
    temporal_analyzer = TemporalModelAnalyzer()
    temporal_results = temporal_analyzer.analyze(keypoints_sequence)

    print(f"   AIè´¨é‡è¯„åˆ†: {temporal_results['quality_score']:.2f}")
    print(f"   AIç¨³å®šæ€§: {temporal_results['stability_score']:.2f}")

    phase_dist = temporal_results['phase_distribution']
    print(f"   é˜¶æ®µåˆ†å¸ƒ: è§¦åœ°{phase_dist['ground_contact'] * 100:.1f}% | "
          f"è…¾ç©º{phase_dist['flight'] * 100:.1f}% | "
          f"è¿‡æ¸¡{phase_dist['transition'] * 100:.1f}%")

    # 5. è·‘æ­¥æŠ€æœ¯è´¨é‡è¯„ä»·
    print("\n5ï¸âƒ£ è·‘æ­¥æŠ€æœ¯è´¨é‡è¯„ä»·...")
    quality_evaluator = QualityEvaluator()
    quality_results = quality_evaluator.evaluate(kinematic_results, temporal_results)

    print(f"   æ€»ä½“è¯„åˆ†: {quality_results['total_score']:.2f}/100")
    print(f"   è¯„çº§: {quality_results['rating']}")

    # 6. AIæ–‡æœ¬åˆ†æ
    print("\n6ï¸âƒ£ AIæ–‡æœ¬åˆ†æä¸æ¶¦è‰²...")
    ai_analyzer = AIAnalyzer()
    results_for_ai = {
        'quality_evaluation': quality_results,
        'kinematic_analysis': kinematic_results,
        'temporal_analysis': temporal_results
    }
    ai_text = ai_analyzer.generate_analysis_report(results_for_ai)

    # ä¿å­˜AIæŠ¥å‘Š
    with open(output_dir / 'ai_analysis_report.txt', 'w', encoding='utf-8') as f:
        f.write(ai_text)
    print(f"   AIæŠ¥å‘Šå·²ä¿å­˜: {output_dir / 'ai_analysis_report.txt'}")

    # æ•´åˆç»“æœ
    complete_results = {
        'video_info': video_info,
        'kinematic_analysis': kinematic_results,
        'temporal_analysis': temporal_results,
        'quality_evaluation': quality_results,
        'ai_analysis': ai_text
    }

    # æ¸…ç†èµ„æº
    processor.release()
    estimator.close()

    return complete_results


def print_results(results: dict):
    """æ‰“å°åˆ†æç»“æœ"""
    quality = results['quality_evaluation']

    print("\n" + "=" * 80)
    print("ğŸ“Š åˆ†æç»“æœæ±‡æ€»")
    print("=" * 80)

    print(f"\nğŸ¯ æ€»ä½“è¯„ä»·")
    print(f"   æŠ€æœ¯è´¨é‡è¯„åˆ†: {quality['total_score']:.2f}/100")
    print(f"   è¯„çº§: {quality['rating']}")

    print(f"\nğŸ“ˆ å„ç»´åº¦å¾—åˆ†")
    dims = quality['dimension_scores']
    print(f"   ç¨³å®šæ€§: {dims['stability']:.2f}")
    print(f"   æ•ˆç‡: {dims['efficiency']:.2f}")
    print(f"   è·‘å§¿: {dims['form']:.2f}")
    print(f"   èŠ‚å¥: {dims['rhythm']:.2f}")

    print(f"\nâœ… ä¼˜åŠ¿")
    for strength in quality['strengths']:
        print(f"   â€¢ {strength}")

    print(f"\nâš ï¸  è–„å¼±é¡¹")
    for weakness in quality['weaknesses']:
        print(f"   â€¢ {weakness}")

    print(f"\nğŸ’¡ æ”¹è¿›å»ºè®®")
    for suggestion in quality['suggestions']:
        print(f"   â€¢ {suggestion}")


if __name__ == '__main__':
    main()