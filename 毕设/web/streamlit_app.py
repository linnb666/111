import streamlit as st
import sys
from pathlib import Path
import cv2
import tempfile
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

from config.config import STREAMLIT_CONFIG, POSE_CONFIG, VIEW_DETECTION_CONFIG
from modules.video_processor import VideoProcessor
from modules.pose_estimator import create_pose_estimator
from modules.kinematic_analyzer import KinematicAnalyzer
from modules.temporal_model import TemporalModelAnalyzer
from modules.quality_evaluator import QualityEvaluator
from modules.ai_analyzer import AIAnalyzer
from modules.database import DatabaseManager
from modules.view_detector import ViewAngleDetector, AdaptiveAnalyzer

# é¡µé¢é…ç½®
st.set_page_config(
    page_title=STREAMLIT_CONFIG['page_title'],
    page_icon=STREAMLIT_CONFIG['page_icon'],
    layout=STREAMLIT_CONFIG['layout']
)


# åˆå§‹åŒ–ç»„ä»¶
@st.cache_resource
def init_components():
    """åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶"""
    return {
        'db': DatabaseManager(),
        'ai': AIAnalyzer()
    }


components = init_components()


def main():
    """ä¸»ç•Œé¢"""
    st.title("ğŸƒ è·‘æ­¥åŠ¨ä½œåˆ†æç³»ç»Ÿ")
    st.markdown("*åŸºäºæ·±åº¦å­¦ä¹ çš„è·‘æ­¥åŠ¨ä½œè§†é¢‘è§£æä¸æŠ€æœ¯è´¨é‡è¯„ä»·*")
    st.markdown("---")

    # ä¾§è¾¹æ 
    with st.sidebar:
        st.header("ğŸ“‹ å¯¼èˆª")
        page = st.radio(
            "é€‰æ‹©åŠŸèƒ½",
            ["è§†é¢‘åˆ†æ", "å†å²è®°å½•", "ç³»ç»Ÿç»Ÿè®¡", "ç³»ç»Ÿè®¾ç½®"]
        )

        st.markdown("---")
        st.info("ğŸ’¡ ä¸Šä¼ è·‘æ­¥è§†é¢‘ï¼Œè·å–ä¸“ä¸šæŠ€æœ¯åˆ†æ")

        # æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
        st.markdown("---")
        st.caption("ç³»ç»Ÿä¿¡æ¯")
        st.caption(f"å§¿æ€ä¼°è®¡: {POSE_CONFIG['backend'].upper()}")

    # ä¸»å†…å®¹åŒº
    if page == "è§†é¢‘åˆ†æ":
        video_analysis_page()
    elif page == "å†å²è®°å½•":
        history_page()
    elif page == "ç³»ç»Ÿç»Ÿè®¡":
        statistics_page()
    elif page == "ç³»ç»Ÿè®¾ç½®":
        settings_page()


def video_analysis_page():
    """è§†é¢‘åˆ†æé¡µé¢"""
    st.header("ğŸ“¹ è§†é¢‘åˆ†æ")

    # è§†è§’é€‰æ‹©ï¼ˆå¿…é¡»æ‰‹åŠ¨é€‰æ‹©ï¼‰
    st.info("ğŸ“ è¯·æ ¹æ®æ‚¨çš„è§†é¢‘æ‹æ‘„è§’åº¦é€‰æ‹©æ­£ç¡®çš„è§†è§’")
    view_angle = st.radio(
        "é€‰æ‹©è§†é¢‘æ‹æ‘„è§†è§’",
        ["ä¾§é¢è§†è§’", "æ­£é¢è§†è§’"],
        horizontal=True,
        help="ä¾§é¢è§†è§’ï¼šä»è·‘è€…ä¾§é¢æ‹æ‘„ï¼Œé€‚åˆåˆ†æè†å…³èŠ‚è§’åº¦ã€å‚ç›´æŒ¯å¹…ã€èº¯å¹²å‰å€¾ã€‚\næ­£é¢è§†è§’ï¼šä»è·‘è€…æ­£å‰æ–¹æ‹æ‘„ï¼Œé€‚åˆåˆ†æå·¦å³å¯¹ç§°æ€§ã€ä¸‹è‚¢åŠ›çº¿ã€‚"
    )

    selected_view = "side" if view_angle == "ä¾§é¢è§†è§’" else "front"

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ è·‘æ­¥è§†é¢‘",
        type=['mp4', 'avi', 'mov', 'mkv'],
        help="æ”¯æŒå¸¸è§è§†é¢‘æ ¼å¼ï¼Œå»ºè®®ä½¿ç”¨ä¾§é¢æˆ–æ­£é¢æ‹æ‘„çš„è§†é¢‘"
    )

    if uploaded_file is not None:
        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
            tmp_file.write(uploaded_file.read())
            video_path = tmp_file.name

        # æ˜¾ç¤ºè§†é¢‘ä¿¡æ¯
        st.video(uploaded_file)

        # åˆ†ææŒ‰é’®
        if st.button("ğŸ” å¼€å§‹åˆ†æ", type="primary"):
            analyze_video(video_path, selected_view)


def analyze_video(video_path: str, selected_view: str = 'side'):
    """æ‰§è¡Œè§†é¢‘åˆ†æ"""
    try:
        # è¿›åº¦æ˜¾ç¤º
        progress_bar = st.progress(0)
        status_text = st.empty()

        # 1. è§†é¢‘é¢„å¤„ç†
        status_text.text("1ï¸âƒ£ è§†é¢‘é¢„å¤„ç†ä¸­...")
        progress_bar.progress(5)
        processor = VideoProcessor(video_path)
        video_info = processor.get_video_info()
        frames, fps = processor.extract_frames(target_fps=30, max_frames=300)

        # æ˜¾ç¤ºè§†é¢‘ä¿¡æ¯
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("åˆ†è¾¨ç‡", f"{video_info['width']}x{video_info['height']}")
        col2.metric("å¸§ç‡", f"{video_info['fps']:.1f} FPS")
        col3.metric("æ—¶é•¿", f"{video_info['duration']:.1f} ç§’")
        col4.metric("æå–å¸§æ•°", f"{len(frames)}")

        # 2. å§¿æ€ä¼°è®¡
        status_text.text("2ï¸âƒ£ å§¿æ€ä¼°è®¡ä¸­...")
        progress_bar.progress(20)
        estimator = create_pose_estimator(POSE_CONFIG['backend'], POSE_CONFIG)
        keypoints_sequence = estimator.process_frames(frames)

        detected_count = sum(1 for kp in keypoints_sequence if kp['detected'])
        st.info(f"âœ“ å§¿æ€æ£€æµ‹æˆåŠŸ: {detected_count}/{len(keypoints_sequence)} å¸§ ({detected_count/len(keypoints_sequence)*100:.1f}%)")

        # 3. ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„è§†è§’
        status_text.text("3ï¸âƒ£ ç¡®è®¤åˆ†æè§†è§’...")
        progress_bar.progress(30)
        detected_view = selected_view
        st.info(f"ğŸ“ ä½¿ç”¨è§†è§’: {get_view_name(detected_view)} - {get_strategy_name(detected_view)}")

        # ç”Ÿæˆå§¿æ€è¯†åˆ«å†…å®¹
        status_text.text("3ï¸âƒ£ ç”Ÿæˆå§¿æ€è¯†åˆ«è§†é¢‘ä¸å…³é”®å¸§...")
        progress_bar.progress(40)

        # å°è¯•ç”Ÿæˆè§†é¢‘
        try:
            pose_video_path = generate_pose_video(frames, keypoints_sequence, fps, estimator)
            st.subheader("ğŸ¦´ å§¿æ€è¯†åˆ«è§†é¢‘")
            st.video(pose_video_path)
        except Exception as video_err:
            st.warning(f"è§†é¢‘ç”Ÿæˆå¤±è´¥: {video_err}ï¼Œå°†æ˜¾ç¤ºå…³é”®å¸§å›¾åƒ")

        # æå–å¹¶æ˜¾ç¤ºå…³é”®å¸§ï¼ˆæ— è®ºè§†é¢‘æ˜¯å¦æˆåŠŸéƒ½æ˜¾ç¤ºï¼‰
        keyframe_data = extract_keyframes_with_poses(frames, keypoints_sequence, fps, estimator, num_keyframes=6)
        if keyframe_data:
            st.subheader("ğŸ–¼ï¸ å…³é”®å¸§å§¿æ€åˆ†æ")

            # æ¯è¡Œæ˜¾ç¤º3å¼ å…³é”®å¸§
            for row_start in range(0, len(keyframe_data), 3):
                cols = st.columns(3)
                for i, kf in enumerate(keyframe_data[row_start:row_start+3]):
                    with cols[i]:
                        st.image(kf['path'], caption=f"æ—¶é—´: {kf['time_sec']:.2f}s",
                                 use_container_width=True)  # ä½¿ç”¨å®¹å™¨å®½åº¦
                        if not kf['detected']:
                            st.caption("âš ï¸ æœªæ£€æµ‹åˆ°å§¿æ€")

        # 4. è¿åŠ¨å­¦åˆ†æï¼ˆä½¿ç”¨è‡ªé€‚åº”åˆ†æå™¨ï¼‰
        status_text.text("4ï¸âƒ£ è¿åŠ¨å­¦åˆ†æä¸­...")
        progress_bar.progress(55)

        adaptive_analyzer = AdaptiveAnalyzer()
        kinematic_results = adaptive_analyzer.analyze(
            keypoints_sequence, fps,
            view_angle=detected_view
        )

        # 5. æ·±åº¦å­¦ä¹ åˆ†æ
        status_text.text("5ï¸âƒ£ æ·±åº¦å­¦ä¹ åˆ†æä¸­...")
        progress_bar.progress(70)
        temporal_analyzer = TemporalModelAnalyzer()
        temporal_results = temporal_analyzer.analyze(keypoints_sequence)

        # 6. è´¨é‡è¯„ä»·
        status_text.text("6ï¸âƒ£ æŠ€æœ¯è´¨é‡è¯„ä»·ä¸­...")
        progress_bar.progress(85)
        quality_evaluator = QualityEvaluator()
        quality_results = quality_evaluator.evaluate(
            kinematic_results, temporal_results,
            view_angle=detected_view
        )

        # 7. ç”Ÿæˆæœ¬åœ°è§„åˆ™å¼•æ“æŠ¥å‘Šï¼ˆå§‹ç»ˆç”Ÿæˆï¼‰
        status_text.text("7ï¸âƒ£ ç”Ÿæˆæœ¬åœ°åˆ†ææŠ¥å‘Š...")
        progress_bar.progress(95)
        results_for_report = {
            'quality_evaluation': quality_results,
            'kinematic_analysis': kinematic_results,
            'temporal_analysis': temporal_results,
            'view_angle': detected_view
        }
        # ä½¿ç”¨æœ¬åœ°è§„åˆ™å¼•æ“ç”ŸæˆæŠ¥å‘Š
        local_report = components['ai'].local_engine.generate_analysis_report(results_for_report)

        # å®Œæˆ
        progress_bar.progress(100)
        status_text.text("âœ… åˆ†æå®Œæˆ!")

        # æ˜¾ç¤ºç»“æœ
        st.markdown("---")
        display_results(quality_results, kinematic_results, temporal_results, local_report, detected_view, results_for_report)

        # ä¿å­˜åˆ°æ•°æ®åº“
        complete_results = {
            'video_info': video_info,
            'kinematic_analysis': kinematic_results,
            'temporal_analysis': temporal_results,
            'quality_evaluation': quality_results,
            'ai_analysis': local_report,
            'view_angle': detected_view
        }
        record_id = components['db'].save_analysis(complete_results)
        st.success(f"åˆ†æç»“æœå·²ä¿å­˜ (ID: {record_id})")

        # æ¸…ç†èµ„æº
        processor.release()
        estimator.close()

    except Exception as e:
        st.error(f"åˆ†æè¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        st.code(traceback.format_exc())


def get_view_name(view: str) -> str:
    """è·å–è§†è§’ä¸­æ–‡åç§°"""
    names = {
        'side': 'ä¾§é¢è§†è§’',
        'front': 'æ­£é¢è§†è§’'
    }
    return names.get(view, view)


def get_strategy_name(view: str) -> str:
    """è·å–åˆ†æç­–ç•¥åç§°"""
    strategies = {
        'side': 'è†è§’+æŒ¯å¹…+èº¯å¹²å‰å€¾',
        'front': 'å¯¹ç§°æ€§+ä¸‹è‚¢åŠ›çº¿+è‚©éƒ¨æ™ƒåŠ¨'
    }
    return strategies.get(view, 'æ ‡å‡†åˆ†æ')


def generate_pose_video(frames, keypoints_sequence, fps, estimator):
    """å°†å§¿æ€éª¨æ¶ç»˜åˆ¶åˆ°æ¯ä¸€å¸§å¹¶ç”Ÿæˆè§†é¢‘"""
    import tempfile
    import os

    # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶é¿å…è·¯å¾„é—®é¢˜
    output_dir = Path("output/videos")
    output_dir.mkdir(parents=True, exist_ok=True)

    # ä½¿ç”¨å”¯ä¸€çš„æ–‡ä»¶å
    import time
    timestamp = int(time.time())
    output_path = output_dir / f"pose_visualization_{timestamp}.mp4"

    h, w = frames[0].shape[:2]
    fps_int = max(1, int(round(fps)))

    # å°è¯•å¤šç§ç¼–ç æ ¼å¼
    codecs = [
        ('avc1', '.mp4'),  # H.264 - æœ€å…¼å®¹
        ('mp4v', '.mp4'),  # MPEG-4
        ('XVID', '.avi'),  # XVID
    ]

    writer = None
    final_path = None

    for codec, ext in codecs:
        test_path = output_dir / f"pose_visualization_{timestamp}{ext}"
        fourcc = cv2.VideoWriter_fourcc(*codec)
        writer = cv2.VideoWriter(
            str(test_path),
            fourcc,
            fps_int,
            (w, h)
        )
        if writer.isOpened():
            final_path = test_path
            break
        writer.release()

    if not writer or not writer.isOpened():
        raise RuntimeError("âŒ VideoWriter æ‰“å¼€å¤±è´¥ï¼Œå°è¯•äº†å¤šç§ç¼–ç æ ¼å¼")

    for frame, kp in zip(frames, keypoints_sequence):
        if kp.get("detected", False):
            vis_frame = estimator.visualize_pose(frame, kp)
        else:
            vis_frame = frame.copy()

        writer.write(vis_frame)

    writer.release()

    return str(final_path)


def extract_keyframes_with_poses(frames, keypoints_sequence, fps, estimator, num_keyframes=6):
    """æå–å…³é”®å¸§å¹¶ç»˜åˆ¶å§¿æ€éª¨æ¶"""
    import time

    output_dir = Path("output/keyframes")
    output_dir.mkdir(parents=True, exist_ok=True)

    total_frames = len(frames)
    if total_frames == 0:
        return []

    # è®¡ç®—å…³é”®å¸§ç´¢å¼•ï¼ˆå‡åŒ€åˆ†å¸ƒï¼‰
    if total_frames <= num_keyframes:
        indices = list(range(total_frames))
    else:
        indices = [int(i * (total_frames - 1) / (num_keyframes - 1)) for i in range(num_keyframes)]

    keyframe_paths = []
    timestamp = int(time.time())

    for i, idx in enumerate(indices):
        frame = frames[idx]
        kp = keypoints_sequence[idx]

        if kp.get("detected", False):
            vis_frame = estimator.visualize_pose(frame.copy(), kp)
        else:
            vis_frame = frame.copy()
            # åœ¨æœªæ£€æµ‹åˆ°å§¿æ€çš„å¸§ä¸Šæ·»åŠ æç¤º
            cv2.putText(vis_frame, "No pose detected", (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

        # æ·»åŠ æ—¶é—´æˆ³
        time_sec = idx / fps
        cv2.putText(vis_frame, f"Time: {time_sec:.2f}s", (10, vis_frame.shape[0] - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

        # ä¿å­˜å…³é”®å¸§
        keyframe_path = output_dir / f"keyframe_{timestamp}_{i}.jpg"
        cv2.imwrite(str(keyframe_path), vis_frame)
        keyframe_paths.append({
            'path': str(keyframe_path),
            'frame_idx': idx,
            'time_sec': time_sec,
            'detected': kp.get("detected", False)
        })

    return keyframe_paths


def display_results(quality, kinematic, temporal, local_report, view_angle='side', results_for_ai=None):
    """æ˜¾ç¤ºåˆ†æç»“æœ"""
    st.header("ğŸ“Š åˆ†æç»“æœ")

    # æ€»ä½“è¯„åˆ†
    st.subheader("ğŸ¯ æ€»ä½“è¯„ä»·")
    col1, col2, col3 = st.columns([1, 1, 2])

    with col1:
        score = quality['total_score']
        st.metric("æŠ€æœ¯è´¨é‡è¯„åˆ†", f"{score:.1f}/100",
                  delta=f"{quality['rating']}")

    with col2:
        st.metric("åˆ†æè§†è§’", get_view_name(view_angle))

    with col3:
        st.markdown(f"**è¯„çº§:** {quality['rating']}")
        if quality.get('strengths'):
            st.markdown(f"**ä¼˜åŠ¿:** {', '.join(quality['strengths'][:3])}")
        if quality.get('weaknesses'):
            st.markdown(f"**è–„å¼±é¡¹:** {', '.join(quality['weaknesses'][:3])}")

    # å„ç»´åº¦å¾—åˆ†
    st.subheader("ğŸ“ˆ å„ç»´åº¦è¡¨ç°")
    cols = st.columns(3)
    dimensions = quality.get('dimension_scores', {})

    cols[0].metric("ç¨³å®šæ€§", f"{dimensions.get('stability', 0):.1f}")
    cols[1].metric("æ•ˆç‡", f"{dimensions.get('efficiency', 0):.1f}")
    cols[2].metric("è·‘å§¿", f"{dimensions.get('form', 0):.1f}")

    # è¿åŠ¨å­¦æŒ‡æ ‡ - æ ¹æ®è§†è§’æ˜¾ç¤ºä¸åŒä¿¡æ¯
    st.subheader("ğŸ”¬ è¿åŠ¨å­¦æŒ‡æ ‡")

    # åŸºç¡€æŒ‡æ ‡ï¼ˆæ‰€æœ‰è§†è§’éƒ½æ˜¾ç¤ºï¼‰
    cadence_data = kinematic.get('cadence', {})
    col1, col2, col3 = st.columns(3)
    col1.metric("æ­¥é¢‘", f"{cadence_data.get('cadence', 0):.1f} æ­¥/åˆ†",
                delta=cadence_data.get('rating', {}).get('description', ''))
    col2.metric("æ£€æµ‹æ­¥æ•°", f"{cadence_data.get('step_count', 0)} æ­¥",
                help=f"è§†é¢‘æ—¶é•¿ {cadence_data.get('duration', 0):.1f} ç§’")

    # å‚ç›´æŒ¯å¹… - ä½¿ç”¨å½’ä¸€åŒ–å€¼
    vertical_motion = kinematic.get('vertical_motion', {})
    if 'amplitude_normalized' in vertical_motion:
        amplitude_pct = vertical_motion['amplitude_normalized']
        rating_info = vertical_motion.get('amplitude_rating', {})
        col3.metric("å‚ç›´æŒ¯å¹…", f"{amplitude_pct:.1f}% èº¯å¹²",
                    delta=rating_info.get('description', ''),
                    help="ç›¸å¯¹äºèº¯å¹²é•¿åº¦çš„å‚ç›´æŒ¯å¹…ç™¾åˆ†æ¯”")
    elif vertical_motion.get('amplitude', 0) > 0:
        col3.metric("å‚ç›´æŒ¯å¹…", f"{vertical_motion['amplitude']:.4f}",
                    help="å½’ä¸€åŒ–åæ ‡ä¸‹çš„æŒ¯å¹…")
    else:
        col3.metric("å‚ç›´æŒ¯å¹…", "æ•°æ®ä¸è¶³")

    # è§¦åœ°æ—¶é—´æ˜¾ç¤º
    gait_cycle = kinematic.get('gait_cycle', {})
    phase_duration = gait_cycle.get('phase_duration_ms', {})
    if phase_duration:
        st.subheader("â±ï¸ æ­¥æ€æ—¶é—´")
        time_cols = st.columns(3)
        ground_contact_ms = phase_duration.get('ground_contact', 0)
        flight_ms = phase_duration.get('flight', 0)

        # è§¦åœ°æ—¶é—´è¯„çº§
        if ground_contact_ms > 0:
            if ground_contact_ms < 210:
                gc_rating = "ç²¾è‹±"
            elif ground_contact_ms < 240:
                gc_rating = "ä¼˜ç§€"
            elif ground_contact_ms < 270:
                gc_rating = "è‰¯å¥½"
            elif ground_contact_ms < 300:
                gc_rating = "ä¸€èˆ¬"
            else:
                gc_rating = "è¾ƒå·®"
            time_cols[0].metric("è§¦åœ°æ—¶é—´", f"{ground_contact_ms:.1f} ms", delta=gc_rating)
        else:
            time_cols[0].metric("è§¦åœ°æ—¶é—´", "æ•°æ®ä¸è¶³")

        time_cols[1].metric("è…¾ç©ºæ—¶é—´", f"{flight_ms:.1f} ms" if flight_ms > 0 else "æ•°æ®ä¸è¶³")

        cycle_ms = gait_cycle.get('avg_cycle_duration_ms', 0)
        time_cols[2].metric("æ­¥æ€å‘¨æœŸ", f"{cycle_ms:.1f} ms" if cycle_ms > 0 else "æ•°æ®ä¸è¶³")

    # è†å…³èŠ‚è§’åº¦åˆ†æï¼ˆä¾§é¢è§†è§’é‡ç‚¹ï¼‰
    if view_angle == 'side':
        angles = kinematic.get('angles', {})

        if 'phase_analysis' in angles:
            st.subheader("ğŸ¦µ è†å…³èŠ‚è§’åº¦åˆ†æï¼ˆåˆ†é˜¶æ®µï¼‰")
            phase_analysis = angles['phase_analysis']

            phase_cols = st.columns(3)

            # è§¦åœ°é˜¶æ®µ
            gc = phase_analysis.get('ground_contact', {})
            with phase_cols[0]:
                st.markdown("**è§¦åœ°é˜¶æ®µ**")
                st.metric("å¹³å‡è§’åº¦", f"{gc.get('mean', 0):.1f}Â°")
                st.caption(f"èŒƒå›´: {gc.get('min', 0):.1f}Â° - {gc.get('max', 0):.1f}Â°")
                st.caption(f"å¸§æ•°: {gc.get('count', 0)}")

            # è…¾ç©ºé˜¶æ®µ
            fl = phase_analysis.get('flight', {})
            with phase_cols[1]:
                st.markdown("**è…¾ç©ºé˜¶æ®µ**")
                st.metric("å¹³å‡è§’åº¦", f"{fl.get('mean', 0):.1f}Â°")
                st.caption(f"èŒƒå›´: {fl.get('min', 0):.1f}Â° - {fl.get('max', 0):.1f}Â°")
                st.caption(f"å¸§æ•°: {fl.get('count', 0)}")

            # è¿‡æ¸¡é˜¶æ®µ
            tr = phase_analysis.get('transition', {})
            with phase_cols[2]:
                st.markdown("**è¿‡æ¸¡é˜¶æ®µ**")
                st.metric("å¹³å‡è§’åº¦", f"{tr.get('mean', 0):.1f}Â°")
                st.caption(f"èŒƒå›´: {tr.get('min', 0):.1f}Â° - {tr.get('max', 0):.1f}Â°")
                st.caption(f"å¸§æ•°: {tr.get('count', 0)}")

    # æ­£é¢è§†è§’åˆ†æï¼ˆç§»é™¤å¯¹ç§°æ€§ï¼Œä¿ç•™ä¸‹è‚¢åŠ›çº¿å’Œè‚©éƒ¨ç¨³å®šï¼‰
    if view_angle == 'front':
        # ä¸‹è‚¢åŠ›çº¿åˆ†æ
        lower_limb = kinematic.get('lower_limb_alignment', {})
        if lower_limb:
            st.subheader("ğŸ¦¿ ä¸‹è‚¢åŠ›çº¿åˆ†æ")
            limb_cols = st.columns(2)

            left_leg = lower_limb.get('left_leg', {})
            right_leg = lower_limb.get('right_leg', {})

            with limb_cols[0]:
                st.markdown("**å·¦è…¿**")
                st.metric("åç§»è§’åº¦", f"{left_leg.get('mean', 0):.1f}Â°")
                st.caption(f"é—®é¢˜: {left_leg.get('issue', 'unknown')}")

            with limb_cols[1]:
                st.markdown("**å³è…¿**")
                st.metric("åç§»è§’åº¦", f"{right_leg.get('mean', 0):.1f}Â°")
                st.caption(f"é—®é¢˜: {right_leg.get('issue', 'unknown')}")

        # è‚©éƒ¨ç¨³å®šæ€§åˆ†æï¼ˆæ­£é¢è§†è§’é‡ç‚¹ï¼‰
        stability = kinematic.get('stability', {})
        if stability and 'shoulder_sway' in stability:
            st.subheader("ğŸ’ª è‚©éƒ¨ç¨³å®šæ€§")
            st.metric("è‚©éƒ¨ç¨³å®šè¯„åˆ†", f"{stability.get('shoulder_sway', 0):.1f}/100")

        # æ¨ªå‘ç¨³å®šæ€§
        lateral = kinematic.get('lateral_stability', {})
        if lateral:
            st.subheader("â†”ï¸ æ¨ªå‘ç¨³å®šæ€§")
            lat_cols = st.columns(3)
            lat_cols[0].metric("é«‹éƒ¨æ¨ªæ‘†", f"{lateral.get('hip_sway', 0):.2f}%")
            lat_cols[1].metric("è‚©éƒ¨æ¨ªæ‘†", f"{lateral.get('shoulder_sway', 0):.2f}%")
            lat_cols[2].metric("ç¨³å®šè¯„åˆ†", f"{lateral.get('stability_score', 0):.1f}")

    # æ·±åº¦å­¦ä¹ ç»“æœ
    st.subheader("ğŸ¤– æ·±åº¦å­¦ä¹ åˆ†æ")
    col1, col2 = st.columns(2)

    col1.metric("AIè´¨é‡è¯„åˆ†", f"{temporal.get('quality_score', 0):.1f}")
    col2.metric("AIç¨³å®šæ€§", f"{temporal.get('stability_score', 0):.1f}")

    phase_dist = temporal.get('phase_distribution', {})
    if phase_dist:
        st.markdown(f"**é˜¶æ®µåˆ†å¸ƒ:** è§¦åœ° {phase_dist.get('ground_contact', 0) * 100:.1f}% | "
                    f"è…¾ç©º {phase_dist.get('flight', 0) * 100:.1f}% | "
                    f"è¿‡æ¸¡ {phase_dist.get('transition', 0) * 100:.1f}%")

    # æ”¹è¿›å»ºè®®
    if quality.get('suggestions'):
        st.subheader("ğŸ’¡ æ”¹è¿›å»ºè®®")
        for i, suggestion in enumerate(quality['suggestions'], 1):
            st.markdown(f"{i}. {suggestion}")

    # æœ¬åœ°åˆ†ææŠ¥å‘Šï¼ˆå§‹ç»ˆæ˜¾ç¤ºï¼‰
    st.subheader("ğŸ“ æœ¬åœ°åˆ†ææŠ¥å‘Š")
    st.markdown(local_report)

    # AIå¤§æ¨¡å‹åˆ†ææŒ‰é’®ï¼ˆç”¨æˆ·è‡ªè¡Œå†³å®šæ˜¯å¦ä½¿ç”¨ï¼‰
    st.markdown("---")
    st.subheader("ğŸ¤– AIæ™ºèƒ½åˆ†æï¼ˆå¯é€‰ï¼‰")
    st.info("ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ä½¿ç”¨æ™ºè°±AIå¤§æ¨¡å‹å¯¹æ•°æ®è¿›è¡Œæ·±åº¦åˆ†æå’Œæ€»ç»“å»ºè®®ã€‚")

    if st.button("ğŸš€ å¯åŠ¨AIæ™ºèƒ½åˆ†æ", type="secondary"):
        if results_for_ai:
            with st.spinner("æ­£åœ¨è°ƒç”¨æ™ºè°±AIè¿›è¡Œæ·±åº¦åˆ†æ..."):
                try:
                    ai_response = components['ai'].generate_analysis_report(results_for_ai)
                    st.subheader("ğŸ§  AIæ·±åº¦åˆ†æç»“æœ")
                    st.markdown(ai_response)
                except Exception as e:
                    st.error(f"AIåˆ†æå¤±è´¥: {e}")


def history_page():
    """å†å²è®°å½•é¡µé¢"""
    st.header("ğŸ“œ å†å²è®°å½•")

    # ç®¡ç†é€‰é¡¹
    with st.expander("ğŸ› ï¸ ç®¡ç†é€‰é¡¹", expanded=False):
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰è®°å½•", type="secondary"):
                count = components['db'].delete_all_analyses()
                st.success(f"å·²åˆ é™¤ {count} æ¡è®°å½•")
                st.rerun()

        with col2:
            if st.button("ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶", type="secondary"):
                cleanup_temp_files()
                st.success("ä¸´æ—¶æ–‡ä»¶æ¸…ç†å®Œæˆ")

    # è·å–è®°å½•
    records = components['db'].get_recent_analyses(50)

    if not records:
        st.info("æš‚æ— å†å²è®°å½•")
        return

    st.markdown(f"å…± **{len(records)}** æ¡è®°å½•")

    for record in records:
        record_id = record.get('id', 0)
        with st.expander(f"ğŸ“¹ {record['video_filename']} - {record['analysis_date']} (ID: {record_id})"):
            # åŸºæœ¬ä¿¡æ¯
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("è¯„åˆ†", f"{record['total_score']:.1f}")
            col2.metric("è¯„çº§", record['rating'])
            col3.metric("æ—¶é•¿", f"{record['video_duration']:.1f}ç§’")
            col4.metric("æ­¥é¢‘", f"{record['cadence']:.1f}")

            # å„ç»´åº¦å¾—åˆ†
            st.markdown("**å„ç»´åº¦å¾—åˆ†:**")
            dim_cols = st.columns(3)
            dim_cols[0].metric("ç¨³å®šæ€§", f"{record.get('stability_score', 0):.1f}")
            dim_cols[1].metric("æ•ˆç‡", f"{record.get('efficiency_score', 0):.1f}")
            dim_cols[2].metric("è·‘å§¿", f"{record.get('form_score', 0):.1f}")

            # æ·±åº¦å­¦ä¹ ç»“æœ
            st.markdown("**æ·±åº¦å­¦ä¹ åˆ†æ:**")
            dl_cols = st.columns(2)
            dl_cols[0].metric("AIè´¨é‡è¯„åˆ†", f"{record.get('dl_quality_score', 0):.1f}")
            dl_cols[1].metric("AIç¨³å®šæ€§", f"{record.get('dl_stability_score', 0):.1f}")

            # AIåˆ†ææ–‡æœ¬
            ai_text = record.get('ai_analysis_text', '')
            if ai_text:
                with st.container():
                    st.markdown("**AIåˆ†ææŠ¥å‘Š:**")
                    st.markdown(ai_text)

            # æ“ä½œæŒ‰é’®
            st.markdown("---")
            btn_col1, btn_col2 = st.columns(2)
            with btn_col1:
                if st.button(f"ğŸ“Š æŸ¥çœ‹å®Œæ•´æ•°æ®", key=f"view_{record_id}"):
                    full_results = components['db'].get_full_results(record_id)
                    if full_results:
                        st.json(full_results)
                    else:
                        st.warning("å®Œæ•´æ•°æ®ä¸å¯ç”¨")

            with btn_col2:
                if st.button(f"ğŸ—‘ï¸ åˆ é™¤è®°å½•", key=f"delete_{record_id}"):
                    if components['db'].delete_analysis(record_id):
                        st.success("è®°å½•å·²åˆ é™¤")
                        st.rerun()
                    else:
                        st.error("åˆ é™¤å¤±è´¥")


def cleanup_temp_files():
    """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
    import shutil
    from pathlib import Path

    cleanup_dirs = [
        Path("output/videos"),
        Path("output/keyframes"),
        Path("output/visualizations")
    ]

    total_cleaned = 0
    for dir_path in cleanup_dirs:
        if dir_path.exists():
            for file in dir_path.glob("*"):
                try:
                    if file.is_file():
                        file.unlink()
                        total_cleaned += 1
                except Exception:
                    pass

    return total_cleaned


def statistics_page():
    """ç»Ÿè®¡é¡µé¢"""
    st.header("ğŸ“Š ç³»ç»Ÿç»Ÿè®¡")

    stats = components['db'].get_statistics()

    col1, col2 = st.columns(2)
    col1.metric("æ€»åˆ†ææ¬¡æ•°", stats['total_analyses'])
    col2.metric("å¹³å‡è¯„åˆ†", f"{stats['average_score']:.1f}")

    st.subheader("è¯„çº§åˆ†å¸ƒ")
    for rating, count in stats['rating_distribution'].items():
        st.markdown(f"**{rating}:** {count} æ¬¡")


def settings_page():
    """ç³»ç»Ÿè®¾ç½®é¡µé¢"""
    st.header("âš™ï¸ ç³»ç»Ÿè®¾ç½®")

    st.subheader("å§¿æ€ä¼°è®¡è®¾ç½®")
    st.info(f"å½“å‰åç«¯: {POSE_CONFIG['backend'].upper()}")
    st.caption("å¦‚éœ€åˆ‡æ¢å§¿æ€ä¼°è®¡åç«¯ï¼Œè¯·ä¿®æ”¹é…ç½®æ–‡ä»¶ config/config.py")

    st.subheader("è§†è§’è®¾ç½®")
    st.markdown("""
    **æ”¯æŒçš„è§†è§’:**
    - **ä¾§é¢è§†è§’**: åˆ†æè†å…³èŠ‚è§’åº¦ã€å‚ç›´æŒ¯å¹…ã€èº¯å¹²å‰å€¾ã€æ‰‹è‡‚æ‘†åŠ¨
    - **æ­£é¢è§†è§’**: åˆ†æå·¦å³å¯¹ç§°æ€§ã€ä¸‹è‚¢åŠ›çº¿ã€è‚©éƒ¨æ™ƒåŠ¨
    """)

    st.subheader("AIåˆ†æè®¾ç½®")
    st.markdown("**ä½¿ç”¨æ™ºè°±AI (glm-4.6æ¨¡å‹)**")
    st.caption("éœ€è¦å®‰è£…zaiåº“ï¼špip install zai")

    # æ˜¾ç¤ºæ™ºè°±AIçŠ¶æ€
    import os
    from config.config import AI_CONFIG
    api_key = AI_CONFIG.get('api_key', '')

    if api_key:
        st.success("æ™ºè°±AIå·²é…ç½®")
        st.caption(f"API Key: {api_key[:10]}...{api_key[-4:]}")
    else:
        st.warning("æ™ºè°±AIæœªé…ç½®ï¼Œå°†ä½¿ç”¨æœ¬åœ°è§„åˆ™å¼•æ“")
        st.caption("è¯·åœ¨ config/config.py ä¸­é…ç½® ZHIPU_API_KEY")

    st.subheader("è¯„ä»·ç»´åº¦")
    st.markdown("""
    **æŠ€æœ¯è´¨é‡è¯„åˆ†ç»´åº¦ï¼ˆå·²ç§»é™¤èŠ‚å¥ä¸€è‡´æ€§ï¼‰:**
    | ç»´åº¦ | æƒé‡ | è¯´æ˜ |
    |------|------|------|
    | åŠ¨ä½œç¨³å®šæ€§ | 35% | èº¯å¹²ç¨³å®šã€å¤´éƒ¨ç¨³å®š |
    | è·‘æ­¥æ•ˆç‡ | 35% | å‚ç›´æŒ¯å¹…ã€æ­¥é¢‘ |
    | è·‘å§¿æ ‡å‡†åº¦ | 30% | è†å…³èŠ‚è§’åº¦ã€èº¯å¹²å‰å€¾ |
    """)


if __name__ == '__main__':
    main()
