import streamlit as st
import sys
from pathlib import Path
import cv2
import tempfile
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

from config.config import STREAMLIT_CONFIG
from modules.video_processor import VideoProcessor
from modules.pose_estimator import PoseEstimator
from modules.kinematic_analyzer import KinematicAnalyzer
from modules.temporal_model import TemporalModelAnalyzer
from modules.quality_evaluator import QualityEvaluator
from modules.ai_analyzer import AIAnalyzer
from modules.database import DatabaseManager

# é¡µé¢é…ç½®
st.set_page_config(
    page_title=STREAMLIT_CONFIG['page_title'],
    page_icon=STREAMLIT_CONFIG['page_icon'],
    layout=STREAMLIT_CONFIG['layout']
)


# åˆå§‹åŒ–ç»„ä»¶
@st.cache_resource
def init_components():
    """åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶"""
    return {
        'db': DatabaseManager(),
        'ai': AIAnalyzer()
    }


components = init_components()


def main():
    """ä¸»ç•Œé¢"""
    st.title("ğŸƒ è·‘æ­¥åŠ¨ä½œåˆ†æç³»ç»Ÿ")
    st.markdown("---")

    # ä¾§è¾¹æ 
    with st.sidebar:
        st.header("ğŸ“‹ å¯¼èˆª")
        page = st.radio(
            "é€‰æ‹©åŠŸèƒ½",
            ["è§†é¢‘åˆ†æ", "å†å²è®°å½•", "ç³»ç»Ÿç»Ÿè®¡"]
        )

        st.markdown("---")
        st.info("ğŸ’¡ ä¸Šä¼ è·‘æ­¥è§†é¢‘ï¼Œè·å–ä¸“ä¸šæŠ€æœ¯åˆ†æ")

    # ä¸»å†…å®¹åŒº
    if page == "è§†é¢‘åˆ†æ":
        video_analysis_page()
    elif page == "å†å²è®°å½•":
        history_page()
    elif page == "ç³»ç»Ÿç»Ÿè®¡":
        statistics_page()


def video_analysis_page():
    """è§†é¢‘åˆ†æé¡µé¢"""
    st.header("ğŸ“¹ è§†é¢‘åˆ†æ")

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ è·‘æ­¥è§†é¢‘",
        type=['mp4', 'avi', 'mov', 'mkv'],
        help="æ”¯æŒå¸¸è§è§†é¢‘æ ¼å¼"
    )

    if uploaded_file is not None:
        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
            tmp_file.write(uploaded_file.read())
            video_path = tmp_file.name

        # æ˜¾ç¤ºè§†é¢‘ä¿¡æ¯
        st.video(uploaded_file)

        # åˆ†ææŒ‰é’®
        if st.button("ğŸ” å¼€å§‹åˆ†æ", type="primary"):
            analyze_video(video_path)


def analyze_video(video_path: str):
    """æ‰§è¡Œè§†é¢‘åˆ†æ"""
    try:
        # è¿›åº¦æ˜¾ç¤º
        progress_bar = st.progress(0)
        status_text = st.empty()

        # 1. è§†é¢‘é¢„å¤„ç†
        status_text.text("1ï¸âƒ£ è§†é¢‘é¢„å¤„ç†ä¸­...")
        progress_bar.progress(10)
        processor = VideoProcessor(video_path)
        video_info = processor.get_video_info()
        frames, fps = processor.extract_frames(target_fps=30, max_frames=300)

        # æ˜¾ç¤ºè§†é¢‘ä¿¡æ¯
        col1, col2, col3 = st.columns(3)
        col1.metric("åˆ†è¾¨ç‡", f"{video_info['width']}x{video_info['height']}")
        col2.metric("å¸§ç‡", f"{video_info['fps']:.1f} FPS")
        col3.metric("æ—¶é•¿", f"{video_info['duration']:.1f} ç§’")

        # 2. å§¿æ€ä¼°è®¡
        status_text.text("2ï¸âƒ£ å§¿æ€ä¼°è®¡ä¸­...")
        progress_bar.progress(30)
        estimator = PoseEstimator()
        keypoints_sequence = estimator.process_frames(frames)

        detected_count = sum(1 for kp in keypoints_sequence if kp['detected'])
        st.info(f"âœ“ æ£€æµ‹åˆ° {detected_count}/{len(keypoints_sequence)} å¸§")

        # â­ å§¿æ€è§†é¢‘ç”Ÿæˆ
        status_text.text("2ï¸âƒ£ ç”Ÿæˆå§¿æ€è¯†åˆ«è§†é¢‘...")
        pose_video_path = generate_pose_video(frames, keypoints_sequence, fps)

        st.subheader("ğŸ¦´ å§¿æ€è¯†åˆ«ï¼ˆç«æŸ´äººï¼‰è§†é¢‘")
        st.video(pose_video_path)

        # 3. è¿åŠ¨å­¦åˆ†æ
        status_text.text("3ï¸âƒ£ è¿åŠ¨å­¦åˆ†æä¸­...")
        progress_bar.progress(50)
        kinematic_analyzer = KinematicAnalyzer()
        kinematic_results = kinematic_analyzer.analyze_sequence(keypoints_sequence, fps)

        # 4. æ·±åº¦å­¦ä¹ åˆ†æ
        status_text.text("4ï¸âƒ£ æ·±åº¦å­¦ä¹ åˆ†æä¸­...")
        progress_bar.progress(70)
        temporal_analyzer = TemporalModelAnalyzer()
        temporal_results = temporal_analyzer.analyze(keypoints_sequence)

        # 5. è´¨é‡è¯„ä»·
        status_text.text("5ï¸âƒ£ æŠ€æœ¯è´¨é‡è¯„ä»·ä¸­...")
        progress_bar.progress(85)
        quality_evaluator = QualityEvaluator()
        quality_results = quality_evaluator.evaluate(kinematic_results, temporal_results)

        # 6. AIæ–‡æœ¬ç”Ÿæˆ
        status_text.text("6ï¸âƒ£ AIæ–‡æœ¬åˆ†æä¸­...")
        progress_bar.progress(95)
        results_for_ai = {
            'quality_evaluation': quality_results,
            'kinematic_analysis': kinematic_results,
            'temporal_analysis': temporal_results
        }
        ai_text = components['ai'].generate_analysis_report(results_for_ai)

        # å®Œæˆ
        progress_bar.progress(100)
        status_text.text("âœ… åˆ†æå®Œæˆ!")

        # æ˜¾ç¤ºç»“æœ
        st.markdown("---")
        display_results(quality_results, kinematic_results, temporal_results, ai_text)

        # ä¿å­˜åˆ°æ•°æ®åº“
        complete_results = {
            'video_info': video_info,
            'kinematic_analysis': kinematic_results,
            'temporal_analysis': temporal_results,
            'quality_evaluation': quality_results,
            'ai_analysis': ai_text
        }
        record_id = components['db'].save_analysis(complete_results)
        st.success(f"åˆ†æç»“æœå·²ä¿å­˜ (ID: {record_id})")

        # æ¸…ç†èµ„æº
        processor.release()
        estimator.close()

    except Exception as e:
        st.error(f"åˆ†æè¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        st.code(traceback.format_exc())

def generate_pose_video(frames, keypoints_sequence, fps):
    """
    å°†å§¿æ€éª¨æ¶ç»˜åˆ¶åˆ°æ¯ä¸€å¸§å¹¶ç”Ÿæˆè§†é¢‘ï¼ˆç¨³å®šç‰ˆï¼‰
    """
    from pathlib import Path

    output_dir = Path("output/videos")
    output_dir.mkdir(parents=True, exist_ok=True)

    output_path = output_dir / "pose_visualization.mp4"

    h, w, _ = frames[0].shape
    fps = int(round(fps))  # â­ å…³é”®ï¼šå¿…é¡»æ˜¯ int

    fourcc = cv2.VideoWriter_fourcc(*"mp4v")
    writer = cv2.VideoWriter(
        str(output_path),
        fourcc,
        fps,
        (w, h)
    )

    if not writer.isOpened():
        raise RuntimeError("âŒ VideoWriter æ‰“å¼€å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆè§†é¢‘")

    estimator = PoseEstimator()

    for frame, kp in zip(frames, keypoints_sequence):
        if kp.get("detected", False):
            vis_frame = estimator.visualize_pose(frame, kp)
        else:
            vis_frame = frame

        writer.write(vis_frame)

    writer.release()
    estimator.close()

    return str(output_path)


def display_results(quality, kinematic, temporal, ai_text):
    """æ˜¾ç¤ºåˆ†æç»“æœ"""
    st.header("ğŸ“Š åˆ†æç»“æœ")

    # æ€»ä½“è¯„åˆ†
    st.subheader("ğŸ¯ æ€»ä½“è¯„ä»·")
    col1, col2 = st.columns([1, 2])

    with col1:
        score = quality['total_score']
        st.metric("æŠ€æœ¯è´¨é‡è¯„åˆ†", f"{score:.1f}",
                  delta=f"{quality['rating']}")

    with col2:
        st.markdown(f"**è¯„çº§:** {quality['rating']}")
        st.markdown(f"**ä¼˜åŠ¿:** {', '.join(quality['strengths'])}")
        st.markdown(f"**è–„å¼±é¡¹:** {', '.join(quality['weaknesses'])}")

    # å„ç»´åº¦å¾—åˆ†
    st.subheader("ğŸ“ˆ å„ç»´åº¦è¡¨ç°")
    cols = st.columns(4)
    dimensions = quality['dimension_scores']

    cols[0].metric("ç¨³å®šæ€§", f"{dimensions['stability']:.1f}")
    cols[1].metric("æ•ˆç‡", f"{dimensions['efficiency']:.1f}")
    cols[2].metric("è·‘å§¿", f"{dimensions['form']:.1f}")
    cols[3].metric("èŠ‚å¥", f"{dimensions['rhythm']:.1f}")

    # è¿åŠ¨å­¦æŒ‡æ ‡
    st.subheader("ğŸ”¬ è¿åŠ¨å­¦æŒ‡æ ‡")
    col1, col2, col3 = st.columns(3)

    col1.metric("æ­¥é¢‘", f"{kinematic['cadence']['cadence']:.1f} æ­¥/åˆ†")
    col2.metric("æ­¥æ•°", f"{kinematic['cadence']['step_count']}")
    col3.metric("å‚ç›´æŒ¯å¹…", f"{kinematic['vertical_motion']['amplitude']:.1f} px")

    # æ·±åº¦å­¦ä¹ ç»“æœ
    st.subheader("ğŸ¤– æ·±åº¦å­¦ä¹ åˆ†æ")
    col1, col2 = st.columns(2)

    col1.metric("AIè´¨é‡è¯„åˆ†", f"{temporal['quality_score']:.1f}")
    col2.metric("AIç¨³å®šæ€§", f"{temporal['stability_score']:.1f}")

    phase_dist = temporal['phase_distribution']
    st.markdown(f"**é˜¶æ®µåˆ†å¸ƒ:** è§¦åœ° {phase_dist['ground_contact'] * 100:.1f}% | "
                f"è…¾ç©º {phase_dist['flight'] * 100:.1f}% | "
                f"è¿‡æ¸¡ {phase_dist['transition'] * 100:.1f}%")

    # æ”¹è¿›å»ºè®®
    st.subheader("ğŸ’¡ æ”¹è¿›å»ºè®®")
    for i, suggestion in enumerate(quality['suggestions'], 1):
        st.markdown(f"{i}. {suggestion}")

    # AIåˆ†ææ–‡æœ¬
    st.subheader("ğŸ“ AIæ·±åº¦åˆ†æ")
    st.markdown(ai_text)


def history_page():
    """å†å²è®°å½•é¡µé¢"""
    st.header("ğŸ“œ å†å²è®°å½•")

    records = components['db'].get_recent_analyses(20)

    if not records:
        st.info("æš‚æ— å†å²è®°å½•")
        return

    for record in records:
        with st.expander(f"ğŸ“¹ {record['video_filename']} - {record['analysis_date']}"):
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("è¯„åˆ†", f"{record['total_score']:.1f}")
            col2.metric("è¯„çº§", record['rating'])
            col3.metric("æ—¶é•¿", f"{record['video_duration']:.1f}ç§’")
            col4.metric("æ­¥é¢‘", f"{record['cadence']:.1f}")


def statistics_page():
    """ç»Ÿè®¡é¡µé¢"""
    st.header("ğŸ“Š ç³»ç»Ÿç»Ÿè®¡")

    stats = components['db'].get_statistics()

    col1, col2 = st.columns(2)
    col1.metric("æ€»åˆ†ææ¬¡æ•°", stats['total_analyses'])
    col2.metric("å¹³å‡è¯„åˆ†", f"{stats['average_score']:.1f}")

    st.subheader("è¯„çº§åˆ†å¸ƒ")
    for rating, count in stats['rating_distribution'].items():
        st.markdown(f"**{rating}:** {count} æ¬¡")


if __name__ == '__main__':
    main()
